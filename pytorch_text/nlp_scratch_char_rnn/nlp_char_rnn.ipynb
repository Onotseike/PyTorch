{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitpytorchpython36conda67ab338b5aea4512a55c45a4f56020b8",
   "display_name": "Python 3.6.10 64-bit ('pytorch_python_36': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIM: Generating names from languages"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext as t_text\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the files from the dataset\n",
    "2. Turn te string to plain ASCII\n",
    "3. Read a file and split it into lines\n",
    "4. Build the category_lines dictionary and a list of lines per category\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "num_letters = len(all_letters) + 1\n",
    "\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "num_categories = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(path): return glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(unicode_str):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', unicode_str) if unicodedata.category(c) != 'Mn' and c in all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in find_files('dataset/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = read_lines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "num_categories = len(all_categories)\n",
    "\n",
    "if num_categories == 0:\n",
    "    raise RuntimeError('Data not found. Make sure that you downloaded data ' \n",
    "        'from https://download.pytorch.org/tutorial/data.zip and extract it to '\n",
    "        'the current directory.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of Categories :  18 \n  List of Categories :  ['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n Test  Unicode to ascii function  O'Neal\n"
    }
   ],
   "source": [
    "print(' Number of Categories : ', num_categories, \"\\n\", ' List of Categories : ', all_categories)\n",
    "print(\"+\" * 89)\n",
    "print( \" Test  Unicode to ascii function \",unicode_to_ascii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Network\n",
    "This network extends the last tutorial’s RNN with an extra argument for the category tensor, which is concatenated along with the others. The category tensor is a one-hot vector just like the letter input.\n",
    "\n",
    "We will interpret the output as the probability of the next letter. When sampling, the most likely output letter is used as the next input letter.\n",
    "\n",
    "I added a second linear layer o2o (after combining hidden and output) to give it more muscle to work with. There’s also a dropout layer, which randomly zeros parts of its input with a given probability (here 0.1) and is usually used to fuzz inputs to prevent overfitting. Here we’re using it towards the end of the network to purposely add some chaos and increase sampling variety."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Network"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Layers\n",
    "        self.input_to_hidden = nn.Linear(num_categories + input_size + hidden_size, hidden_size)\n",
    "        self.input_to_output = nn.Linear(num_categories + input_size + hidden_size, output_size)\n",
    "        self.output_to_output = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, category, input, hidden):\n",
    "        input_combined = torch.cat((category, input, hidden), 1)\n",
    "        hidden = self.input_to_hidden(input_combined)\n",
    "        output = self.input_to_output(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.output_to_output(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get random item from a list \n",
    "2. Get a random category  and random line from that category"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def random_training_pair():\n",
    "    # return category and line pair.\n",
    "    category = random_choice(all_categories)\n",
    "    return category, random_choice(category_lines[category])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each timestep (that is, for each letter in a training word) the inputs of the network will be (category, current letter, hidden state) and the outputs will be (next letter, next hidden state). So for each training set, we’ll need the category, a set of input letters, and a set of output/target letters.\n",
    "\n",
    "Since we are predicting the next letter from the current letter for each timestep, the letter pairs are groups of consecutive letters from the line - e.g. for \"ABCD<EOS>\" we would create (“A”, “B”), (“B”, “C”), (“C”, “D”), (“D”, “EOS”).\n",
    "\n",
    "\n",
    "The category tensor is a one-hot tensor of size <1 x n_categories>. When training we feed it to the network at every timestep - this is a design choice, it could have been included as part of initial hidden state or some other strategy."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. One-hot vector for category\n",
    "2. One-hot matrix of first to last letters (not including EOS) for input\n",
    "3. Long tensor of second letter to end (EOS) for target\n",
    "4. Make category, input and target tensors from a ransom category, line pair"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoryTensor(category):\n",
    "    li = all_categories.index(category)\n",
    "    tensor = torch.zeros(1, num_categories)\n",
    "    tensor[0][li] = 1\n",
    "    return tensor\n",
    "\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, num_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(num_letters - 1)\n",
    "    return torch.LongTensor(letter_indexes)\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category, line = random_training_pair()\n",
    "    category_tensor = categoryTensor(category)\n",
    "    input_line_tensor = inputTensor(line)\n",
    "    target_line_tensor = targetTensor(line)\n",
    "    return category_tensor, input_line_tensor, target_line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 torch.Size([1, 18])\ntorch.Size([6, 1, 59])\n6 torch.Size([6])\n"
    }
   ],
   "source": [
    "c, i,t = randomTrainingExample()\n",
    "print(c.size(0), c.size())\n",
    "print(i.size())\n",
    "print(t.size(0), t.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Network\n",
    "In contrast to classification, where only the last output is used, we are making a prediction at every step, so we are calculating loss at every step.\n",
    "\n",
    "The magic of autograd allows you to simply sum these losses at each step and call backward at the end."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fxn = nn.NLLLoss()\n",
    "learning_rate = 0.0005\n",
    "\n",
    "def train(category_tensor, input_line_tensor, target_line_tensor):   \n",
    "    target_line_tensor.unsqueeze_(-1)\n",
    "    target_line_tensor = target_line_tensor.to(torch.device(\"cuda:0\"))\n",
    "    hidden = rnn.init_hidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    losses = 0 \n",
    "\n",
    "    for idx in range(input_line_tensor.size(0)):\n",
    "        output, hidden = rnn(category_tensor.to(torch.device(\"cuda:0\")), \n",
    "        input_line_tensor[idx].to(torch.device(\"cuda:0\")), \n",
    "        hidden.to(torch.device(\"cuda:0\")))        \n",
    "\n",
    "        loss = loss_fxn(output, target_line_tensor[idx])\n",
    "        losses += loss\n",
    "    \n",
    "    losses.backward()\n",
    "\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate, p.grad.data)\n",
    "    \n",
    "    return output, losses.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep track of how long training takes I am adding a time_since(timestamp) function which returns a human readable string:"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is business as usual - call train a bunch of times and wait a few minutes, printing the current time and loss every print_every examples, and keeping store of an average loss per plot_every examples in all_losses for plotting later."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cuda:0\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\nRNN(\n  (input_to_hidden): Linear(in_features=197, out_features=120, bias=True)\n  (input_to_output): Linear(in_features=197, out_features=59, bias=True)\n  (output_to_output): Linear(in_features=179, out_features=59, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (softmax): LogSoftmax()\n)\n"
    }
   ],
   "source": [
    "gpu_device = torch.device(\"cuda:0\")\n",
    "rnn = RNN(num_letters, 120, num_letters).to(gpu_device)\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 \n",
    "\n",
    "print(gpu_device)\n",
    "print(\"+\" * 89)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1m 43s (5000 5%) 15.3947\n3m 19s (10000 10%) 18.5594\n4m 47s (15000 15%) 13.0003\n6m 21s (20000 20%) 16.8768\n7m 51s (25000 25%) 25.6083\n9m 14s (30000 30%) 14.2657\n10m 35s (35000 35%) 16.7909\n12m 11s (40000 40%) 32.8056\n13m 45s (45000 45%) 14.7963\n15m 17s (50000 50%) 20.8249\n16m 47s (55000 55%) 11.0003\n18m 21s (60000 60%) 12.5695\n19m 54s (65000 65%) 7.9889\n21m 26s (70000 70%) 14.3684\n22m 56s (75000 75%) 8.0294\n24m 26s (80000 80%) 24.1532\n26m 2s (85000 85%) 4.7426\n27m 33s (90000 90%) 12.9787\n29m 4s (95000 95%) 14.5931\n30m 35s (100000 100%) 10.7881\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    output, loss = train(*randomTrainingExample())\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%s (%d %d%%) %.4f' % (time_since(start), iter, iter / n_iters * 100, loss))\n",
    "    \n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the Losses\n",
    "Plotting the historical loss from all_losses shows the network learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x1a5275b9ef0>]"
     },
     "metadata": {},
     "execution_count": 16
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 368.925 248.518125\" width=\"368.925pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M -0 248.518125 \r\nL 368.925 248.518125 \r\nL 368.925 0 \r\nL -0 0 \r\nz\r\n\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 224.64 \r\nL 361.725 224.64 \r\nL 361.725 7.2 \r\nL 26.925 7.2 \r\nz\r\n\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m2243a9e158\" style=\"stroke:#ffffff;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"42.143182\" xlink:href=\"#m2243a9e158\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(38.961932 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"80.37982\" xlink:href=\"#m2243a9e158\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 25 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(74.01732 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"118.616457\" xlink:href=\"#m2243a9e158\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 50 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(112.253957 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"156.853095\" xlink:href=\"#m2243a9e158\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 75 -->\r\n      <defs>\r\n       <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n      </defs>\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(150.490595 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"195.089733\" xlink:href=\"#m2243a9e158\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 100 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(185.545983 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"233.32637\" xlink:href=\"#m2243a9e158\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 125 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(223.78262 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"271.563008\" xlink:href=\"#m2243a9e158\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 150 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(262.019258 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"309.799646\" xlink:href=\"#m2243a9e158\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 175 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(300.255896 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"348.036284\" xlink:href=\"#m2243a9e158\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 200 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(338.492534 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_10\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m516f34714f\" style=\"stroke:#ffffff;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m516f34714f\" y=\"221.996237\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 14 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 225.795456)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m516f34714f\" y=\"187.585524\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 16 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 191.384743)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m516f34714f\" y=\"153.174811\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 18 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 156.974029)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m516f34714f\" y=\"118.764097\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 20 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 122.563316)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m516f34714f\" y=\"84.353384\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 22 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 88.152603)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m516f34714f\" y=\"49.942671\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 24 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 53.74189)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m516f34714f\" y=\"15.531958\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 26 -->\r\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 19.331176)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_17\">\r\n    <path clip-path=\"url(#pbc2aa2d2ae)\" d=\"M 42.143182 17.083636 \r\nL 43.672647 53.496162 \r\nL 45.202113 105.028257 \r\nL 46.731578 116.373058 \r\nL 48.261044 112.744903 \r\nL 49.790509 135.326746 \r\nL 51.319975 133.107091 \r\nL 52.84944 131.594485 \r\nL 54.378906 137.871821 \r\nL 55.908371 140.102618 \r\nL 57.437837 137.89761 \r\nL 58.967302 144.30822 \r\nL 60.496768 144.188162 \r\nL 62.026233 148.558814 \r\nL 63.555699 138.083842 \r\nL 65.085164 152.589784 \r\nL 66.61463 152.001679 \r\nL 68.144095 154.216829 \r\nL 69.673561 146.103827 \r\nL 71.203026 160.022418 \r\nL 72.732492 151.947493 \r\nL 74.261958 158.923789 \r\nL 75.791423 155.82616 \r\nL 77.320889 156.947678 \r\nL 78.850354 161.430992 \r\nL 80.37982 156.665591 \r\nL 81.909285 166.493772 \r\nL 83.438751 162.970877 \r\nL 84.968216 169.595065 \r\nL 86.497682 158.02795 \r\nL 88.027147 171.260233 \r\nL 89.556613 161.808393 \r\nL 91.086078 172.847701 \r\nL 92.615544 161.840087 \r\nL 94.145009 167.923871 \r\nL 95.674475 164.022115 \r\nL 97.20394 169.686382 \r\nL 98.733406 174.440341 \r\nL 100.262871 174.531444 \r\nL 101.792337 170.636314 \r\nL 103.321802 173.577989 \r\nL 104.851268 168.248559 \r\nL 106.380733 171.461104 \r\nL 107.910199 171.737293 \r\nL 109.439664 166.693297 \r\nL 110.96913 180.936767 \r\nL 112.498595 178.868363 \r\nL 114.028061 172.113859 \r\nL 115.557526 179.90766 \r\nL 117.086992 175.137571 \r\nL 118.616457 174.808834 \r\nL 120.145923 172.645839 \r\nL 121.675388 176.895719 \r\nL 123.204854 177.956235 \r\nL 124.734319 180.479302 \r\nL 126.263785 180.458079 \r\nL 127.79325 181.48882 \r\nL 129.322716 177.944272 \r\nL 130.852181 172.492829 \r\nL 132.381647 185.721816 \r\nL 133.911112 190.350722 \r\nL 135.440578 183.649171 \r\nL 136.970043 185.8786 \r\nL 138.499509 182.872166 \r\nL 140.028974 185.226149 \r\nL 141.55844 185.752765 \r\nL 143.087905 193.428657 \r\nL 144.617371 184.732028 \r\nL 146.146836 182.373712 \r\nL 147.676302 191.940353 \r\nL 149.205767 185.848605 \r\nL 150.735233 189.004813 \r\nL 152.264698 189.809981 \r\nL 153.794164 192.358607 \r\nL 155.32363 191.097828 \r\nL 156.853095 183.145505 \r\nL 158.382561 186.54647 \r\nL 159.912026 194.28527 \r\nL 161.441492 185.427966 \r\nL 162.970957 191.902939 \r\nL 164.500423 196.772873 \r\nL 166.029888 182.193668 \r\nL 167.559354 185.334595 \r\nL 169.088819 194.790331 \r\nL 170.618285 196.211632 \r\nL 172.14775 192.515485 \r\nL 173.677216 194.519813 \r\nL 175.206681 192.108973 \r\nL 176.736147 186.801826 \r\nL 178.265612 193.965598 \r\nL 179.795078 187.998502 \r\nL 181.324543 183.504489 \r\nL 182.854009 187.019545 \r\nL 184.383474 197.860171 \r\nL 185.91294 190.533148 \r\nL 187.442405 186.995094 \r\nL 188.971871 194.188999 \r\nL 190.501336 191.142355 \r\nL 192.030802 187.664222 \r\nL 193.560267 192.129909 \r\nL 195.089733 195.408825 \r\nL 196.619198 192.185057 \r\nL 198.148664 193.791949 \r\nL 199.678129 205.998734 \r\nL 201.207595 190.677162 \r\nL 202.73706 204.825412 \r\nL 204.266526 193.510356 \r\nL 205.795991 197.316549 \r\nL 207.325457 203.587667 \r\nL 208.854922 189.816885 \r\nL 211.913853 201.677034 \r\nL 213.443319 188.376931 \r\nL 214.972784 196.886803 \r\nL 216.50225 186.568529 \r\nL 218.031715 205.164542 \r\nL 219.561181 198.172538 \r\nL 221.090646 195.36162 \r\nL 222.620112 193.544227 \r\nL 224.149577 192.743807 \r\nL 225.679043 195.513196 \r\nL 227.208508 199.838991 \r\nL 228.737974 201.70075 \r\nL 230.267439 201.177537 \r\nL 231.796905 199.563681 \r\nL 233.32637 206.71742 \r\nL 234.855836 207.169991 \r\nL 236.385302 203.974549 \r\nL 237.914767 203.472924 \r\nL 239.444233 197.342867 \r\nL 240.973698 197.331893 \r\nL 242.503164 196.413782 \r\nL 244.032629 201.890043 \r\nL 245.562095 199.625017 \r\nL 247.09156 203.620684 \r\nL 248.621026 198.769834 \r\nL 250.150491 200.246044 \r\nL 251.679957 200.896439 \r\nL 253.209422 196.167332 \r\nL 254.738888 203.816293 \r\nL 256.268353 198.87101 \r\nL 257.797819 203.155131 \r\nL 259.327284 203.079985 \r\nL 260.85675 203.673693 \r\nL 262.386215 200.587807 \r\nL 263.915681 195.09636 \r\nL 265.445146 197.570427 \r\nL 266.974612 206.64938 \r\nL 268.504077 200.095482 \r\nL 270.033543 205.082877 \r\nL 271.563008 200.776018 \r\nL 273.092474 202.616403 \r\nL 274.621939 199.559827 \r\nL 276.151405 202.316527 \r\nL 277.68087 199.384423 \r\nL 279.210336 201.868918 \r\nL 280.739801 199.045005 \r\nL 282.269267 197.788178 \r\nL 283.798732 204.148279 \r\nL 285.328198 206.655755 \r\nL 286.857663 207.629286 \r\nL 288.387129 199.802188 \r\nL 289.916594 196.315508 \r\nL 291.44606 199.635573 \r\nL 292.975525 200.864169 \r\nL 294.504991 203.544499 \r\nL 296.034456 204.683572 \r\nL 297.563922 198.492907 \r\nL 299.093387 205.278523 \r\nL 300.622853 206.803799 \r\nL 302.152318 209.879037 \r\nL 303.681784 200.41409 \r\nL 305.211249 205.494754 \r\nL 306.740715 196.598913 \r\nL 308.27018 205.701271 \r\nL 309.799646 199.966081 \r\nL 311.329111 202.349563 \r\nL 312.858577 207.261757 \r\nL 314.388042 201.608536 \r\nL 315.917508 201.149989 \r\nL 317.446974 200.994512 \r\nL 318.976439 195.463491 \r\nL 320.505905 198.057909 \r\nL 322.03537 210.375066 \r\nL 323.564836 203.853161 \r\nL 325.094301 195.129125 \r\nL 326.623767 205.422303 \r\nL 328.153232 200.155935 \r\nL 329.682698 212.232212 \r\nL 331.212163 202.654465 \r\nL 332.741629 205.312631 \r\nL 334.271094 203.624664 \r\nL 335.80056 198.748498 \r\nL 337.330025 211.712244 \r\nL 338.859491 198.146176 \r\nL 340.388956 204.335208 \r\nL 341.918422 211.72652 \r\nL 343.447887 208.858595 \r\nL 344.977353 213.195598 \r\nL 346.506818 214.756364 \r\nL 346.506818 214.756364 \r\n\" style=\"fill:none;stroke:#8dd3c7;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 224.64 \r\nL 26.925 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 361.725 224.64 \r\nL 361.725 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 224.64 \r\nL 361.725 224.64 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 7.2 \r\nL 361.725 7.2 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pbc2aa2d2ae\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"26.925\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3wUdf7H8Vc2nfQeyIY0UqkBQkcQqUoRu6igKNixoFJOf7YryOkhnqd3Ip7lQIQDFCsgHFIDAUIKSUiF9IT0XjaZ3x+bLIlJSAikLHyej8c8JLOzM59M4nu/+c53vmMAKAghhNA7qp4uQAghROdIgAshhJ6SABdCCD0lAS6EEHpKAlwIIfSUUXceLDc3lwsXLnTnIYUQQu95eHjg7OzcYn23BviFCxcICQnpzkMKIYTeCwsLa3W9dKEIIYSekgAXQgg9JQEuhBB6SgJcCCH0VLsBrlar2b9/PzExMURHR7Ns2TLda8888wxxcXFER0fzzjvvdGmhQgghmmt3FIpGo2H58uWEh4djaWnJqVOn2Lt3Ly4uLsybN48hQ4ZQU1ODk5NTd9QrhBCiQbsBnp2dTXZ2NgBlZWXExsbi5ubGkiVLWLNmDTU1NQBcvHixaysVQgjRzBX1gXt4eBAcHMzx48fx8/Nj4sSJhIaGcuDAAUaOHNnqe5YsWUJYWBhhYWE4Ojp2qsjAm8Yz5dGHOvVeIYS4nikdWSwsLJSTJ08q8+fPVwAlKipKWb9+vQIoISEhSnJycrv7CAsL69Cxfr/MX/Wi8vbh3Z16ryyyyCKLvi9tZWeHWuBGRkZs376dTZs2sXPnTgDS09PZsWMHoL1LqL6+vtMt7PbUVFVhYm7WJfsWQgh91aEA37hxI7Gxsaxbt0637ttvv2XKlCkA+Pr6YmJiQl5eXpcUWVNZhZGJCSpDwy7ZvxBC6KN2L2KOHz+ehQsXEhkZSXh4OACrV6/ms88+47PPPiMqKoqamhoWLVrUZUXWVFQCYGxmSnV5RZcdRwgh9Em7AX7kyBEMDAxafe2hh7rnwmJNZRUAJubmEuBCCNFAL+7ErKm6FOBCCCG09CPAK7VdKCbmpj1ciRBC9B56EuDSAhdCiN/TkwBvbIFLgAshRCO9CPBaXR+4jAUXQohGehHgui4UMwlwIYRopB8BXtHYhSIBLoQQjfQiwKvlIqYQQrSgFwEuFzGFEKIlvQjwutpa6uvqMJZx4EIIoaMXAQ7aC5nSAhdCiEv0KMAr5SKmEEI0oUcBXoWptMCFEEJHfwK8qgpjGQcuhBA6+hPg0oUihBDN6FGAy0VMIYRoSo8CvFJupRdCiCb0JsBrK+XBxkII0ZTeBLh0oQghRHN6E+DVchFTCCGa0ZsAr6mswlgCXAghdPQmwGurqjAyNkZlZNjTpQghRK+gNwEuz8UUQojm9CjAZUpZIYRoSv8C3EymlBVCCOhAgKvVavbv309MTAzR0dEsW7as2evLly9HURQcHBy6rEiQLhQhhPg9o/Y20Gg0LF++nPDwcCwtLTl16hR79+4lNjYWtVrNtGnTuHDhQpcXKgEuhBDNtdsCz87OJjw8HICysjJiY2Nxc3MDYN26dbzyyisoitK1VdI0wGUooRBCQAda4E15eHgQHBzM8ePHmTNnDhkZGURGRl72PUuWLGHp0qUAODo6drrQSxcxJcCFEKKR0pHFwsJCOXnypDJ//nzF3NxcCQ0NVaytrRVASUlJURwcHNrdR1hYWIeO1dri2F+tvBd1TBl+2/RO70MWWWSRRR+XtrKzQ6NQjIyM2L59O5s2bWLnzp34+Pjg5eVFREQEKSkpqNVqTp8+jYuLS0d21yk1VdWA9IELIUSjDnWhbNy4kdjYWNatWwdAdHR0s7BOSUlh5MiR5Ofnd02VyDhwIYT4vXZb4OPHj2fhwoVMmTKF8PBwwsPDmTVrVnfU1oymugYAIxPjbj+2EEL0Ru22wI8cOYKBgcFlt/Hy8rpmBbVFU9MY4CZdfiwhhNAHenMnJkBtdTXGphLgQggBehbgmppaDKUFLoQQgN4FeA3GEuBCCAHoYYBLH7gQQmjpV4BX12AkfeBCCAHoWYDXSgtcCCF09CrAtV0oMg5cCCFA3wK8ugZjE3mggxBCgL4FeG2ttMCFEKKBfgW4XMQUQggdvQrw2upquYgphBAN9CrA62prJcCFEKKBXgV4bXWNzIUihBAN9CrA5U5MIYS4RAJcCCH0lJ4FeK2MQhFCiAb6FeDV1RgZG7f7gAkhhLgR6FWA1zY8lUfmBBdCCD0LcE1NLYCMRBFCCPQtwBsfbGwst9MLIYR+BXhtQ4BLC1wIIfQswKvlyfRCCNFIrwK8VgJcCCF09CrAG7tQ5CKmEELoW4BLC1wIIXTaDXC1Ws3+/fuJiYkhOjqaZcuWAbB27VpiY2OJiIhgx44d2NjYdHmxjcMIJcCFEKIDAa7RaFi+fDlBQUGMGTOGp59+msDAQPbu3cugQYMYOnQo8fHxrFq1qsuL1dRUAxLgQggBHQjw7OxswsPDASgrKyM2NhY3Nzf27t1LXV0dAKGhoajV6q6tlCYXMaUPXAghrqwP3MPDg+DgYI4fP95s/eLFi/n555+vaWGt0d2JKS1wIYTAqKMbWlhYsH37dp5//nlKS0t161evXo1Go2HTpk2tvm/JkiUsXboUAEdHx6sq9lIXityJKYQQAEp7i5GRkfLLL78oL7zwQrP1CxcuVI4ePaqYm5u3uw9ACQsL69B2bS0WdrbKe1HHlPH333VV+5FFFllk0aelrezsUAt848aNxMbGsm7dOt26GTNmsGLFCiZNmkRlZWVHdnPVGocRSheKEEJ0oAtl/PjxLFy4kMjISN3FzNWrV/PBBx9gamrK3r17Ae2FzCeffLJLi9XoppOVLhQhhGg3wI8cOdLqAxR8fX27pKDLqdNoqK+vx9jUtNuPLYQQvY1e3YkJ2m4UmU5WCCH0McBra2QcuBBCoI8BXi0BLoQQoI8BXlOLkbEEuBBC6GGA18h0skIIgR4GeG11tdyJKYQQ6GGAa2pqMTKRYYRCCKGHAS4XMYUQAvQ1wKULRQgh9DDAq2swli4UIYTQvwCvramRuVCEEAI9DHAZRiiEEFr6F+DVNfJMTCGEQB8DvLZWAlwIIdDHAJcWuBBCAHoY4JVlZZj2McdI5gQXQtzg9C7AC9IzALDv59rDlQghRM/SuwDPT88EwMFd3cOVCCFEz9K/AE/TtsAd1P16uBIhhOhZehfgZQWFVFdU4ODu1tOlCCFEj9K7AAdtK9xBLQEuhLix6WeAp2dKC1wIccPTzwBPy8DBrR9+Y0NYtO4vGBgY9HRJQgjR7Yx6uoDOyE/PwNjMlDtfewVHdzV9bKwpLyru6bKEEKJb6W0LHMCxYSihubVVT5YjhBA9Qj8DvOFmnkZ9bKx7qBIhhOg57Qa4Wq1m//79xMTEEB0dzbJlywCws7Njz549xMfHs2fPHmxtbbu82EaFmdlUV1SQdjYWAHNrCXAhxI2n3QDXaDQsX76coKAgxowZw9NPP01gYCArV65k3759+Pn5sW/fPlauXNkd9QJQp9Hwt7sXsfX1vwDQR7pQhBA3oHYDPDs7m/DwcADKysqIjY3Fzc2NefPm8cUXXwDwxRdfcPvtt3dtpb+Tl5pOSV4eIF0oQogb0xWNQvHw8CA4OJjjx4/j4uJCdnY2oA15Z2fnVt+zZMkSli5dCoCjo+NVlttcZXEpIBcxhRA3pg5fxLSwsGD79u08//zzlJaWdvgAGzZsICQkhJCQEPIaWszXSp1GQ3VFpQS4EOKG1KEANzIyYvv27WzatImdO3cCkJOTg6urdkpXV1dXcnNzu67Ky6gsKZEuFCHEDalDAb5x40ZiY2NZt26dbt2uXbtYtGgRAIsWLeK7777rmgrbUVFSKhcxhRA3pHb7wMePH8/ChQuJjIzUXcxcvXo1a9asYevWrTz66KOkpqZy9913d3mxraksKZVhhEKIG1K7AX7kyJE25xqZOnXqNS/oSlUUl+DYXx7uIIS48ejlnZhNaVvg0oUihLjx6H2AV5SUYG4lAS6EuPHof4AXl2DaxxxDY+OeLkUIIbqV3gd4ZYl2TLqMRBFC3GiumwCXfnAhxI1G7wO8orgEgD42Nj1ciRBCdC/9D/AmLXArRwee/c8n3PzIAz1clRBCdD29D/DKEm0L3MXbk6c++weeQwczYs6sHq5KCCG6nt4HeGMXysxnlmDj4kzEnv309fXBwla6VIQQ1ze9D/DK0jIAjE1N2fXuBxz86hsAvIYP7cmyhBCiy+l9gCv19RTl5BJ76Cih274l7WwstVXVeI8M7unShBCiS13RAx16q/ULHqO8sAiAutpazkdE4T1iWA9XJYQQXUvvW+AAJbkXqaut1X2dfOoMbv6+WNjaYOvizJ2vvYJpnz4t3hdy+20Ym5l2Z6lCCHHNXBcB/nuRvx5AURTmrXieBWveYNw98wmcOLbZNu6Dgrjv7VcZfMukHqpSCCGuznUZ4NkJSfz6yeeMmD0Tn5HB1NfX4/W7LhVnz/4A2Lq69ESJQghx1a6LPvDW/Lrhc7yHD6MwOxtbF2e8fzcqxdHDHQAbZ6eeKE8IIa7addkCB6jX1PHPJc/yzWt/Ivl0BK6+PphZWeped2oIcGsJcCGEnrpuA7yp5FNnUKlUeA0bolsnLXAhhL67IQI8NeosmtpaQm6/jeG3TUdlaKhrgdu4SIALIfTTddsH3lRtVTXnwyMZOn0KQ6dPwcbZCTMLCypKSrBysMdApUKpr+/pMoUQ4orcEC1wgM9fWMW7dz5IfnomkxYtACD5ZDiGRkZYOdg323bwLZNkLhUhRK93wwR4ZUkpWfFJhP+8VxfYiWHhQPN+cBsXJx5+fw2j75zXI3UKIURH3TAB3ij8pz0AaGpruRARBTTvB3cL8AfArq+MDxdC9G43RB94U9mJyWTGJ6JSqSjMygGat8D7Bfhq17k490h9QgjRUTdcgANsWvkGxqamlBUUUqfRNBsL7uavDXBbCXAhRC/XbhfKxo0bycnJISoqSrdu6NChHDt2jPDwcMLCwggJCenSIq+17IQk0qJjUOrrKc3Lb9YCdwv0A2R4oRCi92s3wD///HNmzpzZbN3atWt58803CQ4O5v/+7/9Yu3ZtlxXY1YpzLuIW4MvMZ5fi6uuDg9qNypJSLO3tMDIxYdLC+3H19enpMoUQooV2A/zQoUMUFBQ0W6coCtbW1gDY2NiQmZnZNdV1g6KcXPr5+zJt6SM8/q/3AYg7EgpoW+NzX17GTQ/c05MlCiFEqzrVB/7888+ze/du3n33XVQqFePGjWtz2yVLlrB06VIAHB0dO1dlF9r9jw3E/HYEIxNj7n59JQAxB48QPGsaQTeNB6D/kIE9WaIQQrSqU8MIn3zySV544QX69+/PCy+8wMaNG9vcdsOGDYSEhBASEkJeXl6nC+0qOcnnObnrJ0L/+x2nf9zNxQtppEXHAhA0SRvgLj5emFla9GSZQgjRQqda4IsWLeK5554DYNu2bXz66afXtKiesnnVmxiamKBSaT/X+jWMSFGpVPQfHETAhLEUZGRy5OvtKIrSk6UKIUTnWuCZmZlMmqR9ks2UKVNISEi4pkX1FEVR0FRXU1NZSUVJCQCJJ05RX1/P1KWPMGnh/cxftZyH169BZWiIOiiAF775HHNrqx6uXAhxI2q3Bb5582YmT56Mo6MjaWlpvP766yxZsoT169djZGREVVWVro/7elKUnUsfa2uSToZjYWeLz8hgCrOyObHje2Y8vYQBo4YzZPoU1EH+qIMCSAgN071XZWTIhAV3c3TLDjQ1NT34XQghrmftBviCBQtaXT9y5MhrXkxvUpyTSz+/AWTExWPr4kxfXx/2ffolYd/+yKRFCxh+2wwCJmifs+ns5dEswH1HjWTey89RkJ5J9P6DPfUtCCGuczfknZgdUZSTC0BmXAJVpWWY21hzYucP1NXWEv2/g4yYPROVoSGgDfCm7NX9AHnephCia0mAtyH+WBj2fV0pzMqmMCubpJPhutfO/PwrI+fMora6mvy0jBYB7qB2A8Cur2u31iyEuLHccLMRdlTknv188sQLrb4Wf+wE5YVFxB0OJe1sXCsB3tgCd8bE3JwH176FXV9XVEaG3PPmapw8+3d5/UKI658EeCfUaTR8uOgJ/vvWO+SmXMDWxRlbVxdmPrMUI1NTXQvctq8LnsMGETxrGgETx+Lq483oO+Ywev6cHv4OhBDXA+lC6aTclAvN/nvX6ysInDCWjNhzzfrAnb08AXDsr6a8sAgAn5DhAIy/707OHjhMUXZO9xYvhLguSAv8Kl08rw3wwIYRKUGTJ2BuZUllSSnWTo708xsAgKO7Gw7u2pa5OsifgIljueMPL3HTwvt6pnAhhN6TAL9KeWkZ1Gk0AJQXFTNk6s0AJJ+OQKVS4TtGO9Wug7saR3c1ACpDQ+78w8sA+I8d1QNVCyGuBxLgV6mutpa81HQyzyVwfPt3ujlTkhtGrdi79QW0I1McPdxJjzmHpqYGe7e+VJaW4TrAu9kDJdrj6OHOsv9swNLe7tp/M0IIvSIBfg18+dKr/Pv5laSEX3roRdNhh3mp6ZiYm9F/UBDZiclciDwLwPfvfgCA35i2H4jh7OWBpcOlsA6ZeyseQwehHhhwrb8NIYSekQC/BrITkihIz+T8mUgASvMLyElO0b1+9rfDAJiYm5GXls6RLds5vn0XJ3b+QGl+AX5jWw9wA5WKp/79EQ/99Y+6dUGTJwDNn+MphLgxySiUa6iiuITspBSqysqoqayivKgYC1sbYg4cZtJD2ouV+WnpROzeR8TufQAkHD+J39hRGBgYtJjh0H1QIFYO9lg52OM5dDAleXm6i6LyzE4hhAT4NfbNa3+kMYeLsnMwMjEh5XQEdbUaDI2NyEtNb7Z9zG9HGH7rdDyGDOJ8RBQGBgY88enfOfvbYcytrKivq6OytIxbli4i/ugJAGqrq6UFLoSQAL/WUqNidP/OPJdIRVEJdRoNhVnZOPZXk5+W0Wz72INH0NTWMnjqZM5HRDFg9EgGjBqBemAAJbl5XIg8S9zhY8x69nGCbhpPdlIKNZWV2DRpgbv6+mBiZtrs2FdKZWhIfV1dp98vhOh+0gfehba9uYaNz74EaC9kVpaUUl5U3GybqrJyEkLDGDx1MgBj7pxLVVk5JmZmOHt5EHvoKPs3fsWW1/7I4c3b+OFv/6A45yI2Lpda4He9+jIPrHmzxfGnLn2Yxz9Z36Fal23awG3PP9nJ71QI0ROkBd6F6mprqavV/vvYtm9JOnm61e0i9x7g3rdWM2jKJAbdMomjW3Zgbm1JyLzbiDt8jPq6OsK+/ZGwb38EIGDCGHxCggEwNDbGfVAgRiYmmFlZUlVaBoDPyGBmPL1E9zShy7XOHdzVuA8MpKK45Bp+90KIriYB3k2i9//W5mtnDxyirlbDI+vXABC6/TtK8/JJCD1JRmx8i+2Lc7QPmzAxN6Ov3wCMTEwAcAvwozAziwkP3EPwrGnkp2Vg6+LMiNkzLxvgARPGADJ7ohD6RgK8FygvLOKjR57CZYAXFUXF5CRphyCe+uGXVrcvzrkIgLWzE55DB+vWqwP9mfb4I3gFDyE1KoYdf36PWx5byLCZU/nur+up17Texx0wXhvgMn+5EPpFAryXOB8RxfmIqPY35NLDJmycnfAcNpi8tHSMjI3xHzcKn5HB7Nv4Jb/8/RMATv2wm+BZ0wiZdxvHt+9qsS9DY2N8QoZTXVGJaR9z+thYS1eKEHpCLmLqoeJcbQvc1sUZz2GDOX8mivSYOPzHj0FlaEjU3gO6bc8dDeVC5FnueWMVd/zhpRb78h4xDNM+5pz55VdAulGE0CcS4HqopCHAB4wagbWTozbAG/rK89MzyYi71G9er6njH4ue4OBX3zD+vjsZNuOWZvsKmXcrVWXlnPz+Z0A7h7kQQj9IgOuhmsoqKkpKGDV/NtUVFcQePEr62TgAovYdaLF9nUbDrnc/IC0mjrmvPIeTZ3/Mra2wcnRg6IxbOLHzB3JTzgPSDy6EPpE+cD1VnHORPtbWbP/juxRl51BZWkrMb0cI/e93rW6v1Nez449/5dn/bGDl99+gqakh7WwcKkNDDn/9X8oLiqitrsZOAlwIvSEBrqfCf9pLrNVRTjV0fVSXV7DxmZZ93E2lRsXwj4VP4OTVn8CJ4xg6fQpnDxwmP017e39xzsVOdaEYGhtjbm1JWX7hlX8jrbBX98PEzIzsxORrsj8hrmdKdy1hYWHddixZ2l+8RwYrlg52uq+f+PTvyjNf/qvFdha2Nsr8VS8qNi5Ore5n8Qdrldf2ftuhY3oOG6I4qN0uu83iv/9Veevgz4qJuVmnvi+VkWGPn1tZZLmWS1vZKX3gN7Dkk+HNWs1F2bnYNbTAXbw9eeW7r+nrN4Bblj7MhAV3c++bq1vsI/jW6Qy8eSK2ri4desjEI+vX8ODaty67jb1bXyzsbBlz9+1X+B3BsBm38Pah3TJbo7ghSIALnaLsHKydHFEZGhI0eQIu3p489Ne3GXfPfAoysvAfP4YJC+7GQKX9tTExN2P+yhd048advT0vu3+7vq5Y2tvRf3AQXsOH6tabWVk2265xpsWbH34AI1PTK/oeRt85FzNLC8bff+cVvU8IfdRugG/cuJGcnByioprfZPLMM88QFxdHdHQ077zzTpcVKLpPUXYOKkNDbF2148uryspx8fZEpTLkn489S+KJU8xf9SKv7tmJg7uafv5+WNjZ8ss/NgDg4uWJ94hhzFvxfKv7dwv0A7SjYiYvuh8Az6GDefvQL/T18wHAyNSUPjbWJISexNrJkaBJ4ztcv6W9HQNGjUBTW8uYu27H2OzKwl8IfdNugH/++efMnDmz2brJkyczb948hgwZwqBBg3j33Xe7rEDRfS5ERgPgP24MnkMHE/nr//j+vQ/5/r2/k5+ewYYnX+Srl1/D1sWZIdMm09dXG7oxvx2muqICZ28PJiy4m5sevJegSRNa7N8twI/6ujoObdpK0OSJ2huRgoegMjTEb4z24c42To4AnNmzj/q6OvoO8L5szXe9vgKfkOEADJ46GZWhId+98z59bKwZMWeWbjszK0umPv6Ibt6Y7mDXz5XX93+Ps5dHtx1T3FjaDfBDhw5RUFDQbN2TTz7JmjVrqKmpAeDixYtdU53oVlnxSVw8n8rkhxdgaW/H+fBIDny+iUObtgKgqanhzC+/kp+egToogL5+PlSWllGYmU1uygVcfbzwGamdJXHq0odb7N8twI/c86mE/7RXO0vikIG4NgS09whtl0rjNLkF6Rnkp2Xg4uPVZr19/XwYe9ftjLlzLgDDZk4lOymFo9/s4OKFNN0cLwCTHrqPWc8sxX/cKN26Wc8+zt2vr7yKM9Y664YPIc+hg7F2cqSfv+81P4YQ0Mk+cD8/PyZOnEhoaCgHDhxg5MiRbW67ZMkSwsLCCAsLw9HRsdOFiu4RsWc/jv3VAJw/0/rcLOkx51AH+ePq660b6peTfB7vEcOwtLcj+dQZPIYMJGTerc3e5xboR2ZcPNmJydTValAHBeDqqw1wr+CGAG/o/y7OuUhOyvnLtl4DJowFwH1QEGaWFngPH0rUrwca6knBwd0N0A5zHHvPfO22g4MAsHKwZ/LDCxg1fzZWDvZXdpIuw3PYEF7f/z19/Qbg5OEOgKW97TXbvxBNdSrAjYyMsLOzY8yYMbz88sts3bq1zW03bNhASEgIISEh5OXldbpQ0T0i9/4P0D7fMzflQqvbpMfE4eiuRh3oT1ZCEgC5yRd03RNb3/gLGXHx3PfH13ji079jZGKChZ0ttq4upMecQ1NTQ3ZiMu6DAnH19qI0vwALO1ucvTwuBXjuRXKSzuPk2R+VoWGrdQROHAeAk4c7g2+ZhMrQkITQMED7AA1Hd+0H0bCZU7FysKe6ogKPwQMBGHfvHRiZmKAyNGTI9CmdPl9TH3+EIdNu1n3d+IHkMXQQTp79AbCwa390jhCd0akAT09PZ8eOHQCEhYVRX18vrevrREZcPDnJ50kMO93iIcuN0mO0t+2b9ulDdkOA5ySfB6AgI4uL51N5//7FfPvO+/iOHsmkRffjPjBAt//GffiMCMbYzJTjO74HwGv4UKxdnKiuqKCqrJyc5PMYGRvrWtJNmVlZ6ibyApj8yIPUVlVzIfIsoA1wE3MzrJ0cGXvXPLKTUjj1w27cBwZiZGrK2Hvmc/bAYbISklrMD9PUoCmTWPz3v7b5+uSF93PzIw/qvrZ11Q5f7Oc3AMfGFridtMBF1+hUgH/77bdMmaJttfj6+mJiYiKt6+vIR4ufYuvrf27z9fSYc7p/61rgDXOpND51qF5Tx6H/fEPEnv1MXfIw9779KhXFJbrwT489h6Gx9kbg6P0HKc0vwHv4MGycnXTznec2fCi4NBme2DiE0W/sKAyNjNjzz8+or6/H1ceLlDORaBquyzTeXeo6wAv3wUHE/HaY1KizmFtbMfuFp7BysOfgV1sI/3kv3iOG6caNDxg1AlOLPrrj+Y8fzcDJE5qta2Tapw/m1laog/x1QyFtXbTj6Pv5DcDJo7EFLgEuuka7Ab5582aOHTuGv78/aWlpLF68mM8++wxvb2+ioqLYsmULixYt6o5aRTcpyy+ksqS0zdcrikvIT88ELgV4Xmo60ft/48TOH5ptu+uvH6Ao9dRUVPLhwsepKisHLrXi6+vryUlKJvH4SfzHj8bW1Vk3XW5jF46Lt/ZC5vQnH2Xl999g5ejAlMUPUnIxj4TQMN0DMBJPnNIdNy9VG+CDp96MkbExadGxuqcSTXzgHlJOR5B44hThP++lvr6eMXffju+YEJ7c+CGP/2s9pn20gW3t5ACgC/jGDxC4dMFVZWiIz4hhALobodwHB2HeEOqt3eBk7ezEHX94iQfWvIGBgUGb51qIy2l3LpQFCxa0uv6hhx665sUI/ZEaGQ0ouqCvr6vj38+1HNFRlJ3D2nkLqCguoaayUrc+Mz6JOo2GwsxsaiqriN5/kOBbp2Nha8Ppn/YAUF1RQWFWNs7eHpiYm3HTQ/dhbmXJi9u+wNrRgS9fepX6upTdl4kAABn2SURBVDpSo2Lo6+vTLMCLsnPR1NYytKF/OzUqhuLci1SVlWNmacHujz4FoCA9k+j9Bxl/350MCBlORUkJ6oEBPLj2LTY+85JuRImNizNuQf7MfWkZ78y9n8qSEl13CcCAUSM5e+Awtq4u1NfVYWRsDEBlaVmLFrj7wECe/OxDjM3MUKlUxB4+xukfdl/tj0TcgOROTNEp377zPp883voNO79XlJ3TLLwBNNXVpEbF6Maexx4+hqa2FpWhoW6+c4CcpPN4DB7IqPlzMLey5OjWnVg7OhDz2xEidu8DIPynPcQeOkra2Vjd++rr6ihIz8TC1obS/AKKsnNQ6uuJDw3j3NHjJBw/qdv2f599RR8ba7yGD2XfJ19waNNW/MePRmVo2CTAtY+vs3KwZ+ScmQ3rtAGel5rOgNEjMDAwwNbVudnonQsR0c36wG1cnHjkg3coKyhizex7SYuJY9azj3fr+PSO8h4ZjDoooKfL6BKGRkYYNnzINuXgrsZz2JAeqKhzJMBFp5QVFOq6KTprw5MvsO1N7YOcq8srdKFanHvpekrYtz/g0F/N/FUvkhEXz/a31/LJEy+wadUbum0Sjp/k06eWt3jmZ15DP3jTBzp/+eJqPn1qebPtUqNiSDxxivKiYo5t+5bc5PMYGhlh29dFN8TQxsUZB7X2YmrjHC2Nc6ef+uEX+vkNwMXHCyMTE2IPHQO04+bTY+LoY2uj63q5960/YNqnD589+zL5ael8/9cPsO/XlzF3zb2KMwkWtjYd287OVjdW/3IMDAx4aO1bPPbRe5hbW11Vbe2xdnKkj411lx7j9x5+fw1PffaPFt1Xs194ioXv/bFba7kaEuCix1SXV1BbVa37Onrfb8ClR8YBnNm9j80r36C2upoDX2wG4NyRUKpKy9rdf+MHTNOWuaIo1Ne1fLjzly+9yvoFj1FdUUFBZjag7eowNNL2Mtq6OOOg7kd1RSWuPl54BQ/BxsWJ0vwC4g5rA3tkw52fOckp5KdnkJeaTml+PiqVij421viNHYX/uNH88o8NuvHzSSfDSYuJa3bXaEe5DwrCb+woHlm/hrcO/YJ3B4L5tuee5PFPPsDE3Pyy2/X1G4C1kyNWDvbcuuyJK66to1SGhjzz5T959MPO381tYGDAsk2fMmL2zPY3BkzMzfEbNwrPYYMJuX12s9f6+fti4+yEmaVFp+vpThLgotcI/3kvhzZtbda90bj+D2OnXXE/ceNIlLTomHa2hPLCIt32BRlZgPZOyka2fV2wc+vLiZ3fU1VWzvDZM7F1caYoJ5f0mHNUlZUzoqFrpSgrh4NffcPRrTspKygCtDcOzX7xafLTMzn6zY5mxz794276DwrSDTvsiIAJY3j+6408/sl6fMeMQlNTw+Apky77HpWhIYOm3IShsRFuAZe/O9R//GhtbT/tYczdt19Rbb83YvZM7n37D80uADcaNOUmHNRueA4b3GyCs9/XfTm2fV3wGDKQgIljO1TPgFEjMDI2piQvn1ufe0I3gsjE3Ax7dT8AHPtf2ffbf8hA3Xu7kwS46DWqyyv4ds26VlvXdbW1V7y/swcOc/rH3SSfOnNF7yvKzqG+vh6PoYMAKM0vwGPwQIyMjclKSCL51BkGhAzH1tWF4uwc6uvqSDoZrusvL8rO4fDmbRz5+r+UF2oDPGjSeNwC/Nj7r89afC9nftlHfX09w2+d3uEa/caOoraqmo8WP82fb72ThBOnCJgwptk2xmamPPTXt3Xz0viMDNZdUFUHBeAW4MftK19oNVgDxo8h81wCv/7r39ppDxruYO2Ipt0htz3/JAv+8jqjbp9NP/8BLba96cF7yU/PoKygsNl4+kZ2/Vz507FfGTBqRJvHcx2gnZPH9TLTLjTlP24U1RWVfL36Tawc7PFt2LeLjzeqhnPReBPW5dzzxioGT50MwEN/fZv5K1/s0PGvJQlwcd0qzMxm08o3qKmsuqL31dXWUnIxD3WgP6DtgmkMpYL0TJJPhePs5YFjfzVFDWPWG0fA1FRWUV5UrNtXWaF2vvXGED135HiL45XkXiQp7DQj5szUXViz6+vKyh+2MnlR66PAfEYO53xEFElhpynLL+TckeM4e3kQMGEMq37ahlfwEAImjGXYzKk8/P5fGDn3VoZMu5nqikpK8wtQBwUwadH9THzgnhZ94ibm5ngGDyHuSCgXU9PQ1Nbi6uONytCQUfPntLj4Z+vizJu//UTwrdNxcFfz2t7vmLP8WXxChjPl0YVE7NkPgPeI5sdxC/TDa/hQDv1nK4e//i8DJ08geNa0Ztv4jxuNibmZ7q7bpsytrTEwMKBvw92vzl4eqAwNGXfvHc3+evo9/3GjSTp5mrSz2vsZ7Pr1BWg2cZqThzvWzk54Bbd+QdPJsz+j75zLkGk3ozIyxNbVBa/hQ1v9MOxKEuBCtKIwI0t3o1HTG5fy0tJJOhkOgLGpKUXZOQC6bp/Grxs1dqF4DB1EQWYWJRdbv+Htty+34Oiu5q7XXsEtwI/HN3yAk4c7QZNbzupobm1FvwBfXR2gvS4A8PC6NTi6q5nwwD0MvmUS5UXFnI+I4v4/vca4e+8g7vAxUqNi8BgykMCbtKE4/LYZzfYfMHEsRsbGnDtynHpNHRfPp+Lq40XAhLHc+9ZqRs6ZiZmVJQ+9+0f6DxnIlMcWYmlvx5zlzzD7hacahnzey93/t4Ki7Bw2r36L/PQMvH/XReI3JgTQdiEd/GoLyafO8ODat5jy6KUhyo0fLp7Dmgeyibk5r+7ewfj779JNiGZkYoJ6YADzV73Iwr/9qdk882ZWlgybcQu3PvckTp79OXfkOJUlJVSVlWPXzxUAVz8faiqrKMjMwsmzP3NfepbHPvpbqz+vQVNuAsDO1QUbJydUKhXmVpbtdk1daxLgQrSiIFPbD67tG88AoK5WQ1F2Lumx56iu0A6LLM7JBSA7IYnywqIWAV5epA1wlUpFasNt/q2JPXiEPf/8jFHzZ/Piti+wcrAn4fhJ1EEBLfqAvYcPRaVSkRR2WrcuN+UCBRlZGJuZkhEbz6CbJxI0aQJnDxziX48tY9OqN4g9dJRD//mG9Jg4nDz708famqLsHIZMu7nZMMYpjz5EXmq6ruspJykFlwFeeA3XtkaDGlrKw2bcwuIP1jL6jjmknI7AxtmJIdNu5ujWnZQXFePk2Z9fPvwETXU1yaciWvRxuwX6U5CRRXlRMdXlFfzzsWc5s3sfM59eqpvErPHCrDrIv1nL38XbEzNLC4bNnIrrAG/dB+OE++9CZWiIjbMTtz3/FKC92PvG/37goXf/yM2LH6QgI4vo/Qd1P2d7t4YWuK8P2UnJ5CZrZ9YMGD8GM0uLVu+k1QV4P1fdcNKm9XYXCXAhWtEY4MUX83SjYgoys1Dq66nX1HEhQjvWu7ELRVEUvvm/P7Hn443N9lOvqaOiRPvEoguXCXCAPR99yo/vf8S2t97hz7Pu5MTO7zHtY95iSl3vkcHUNoyjb2rfxi/Zv/FLNv/hLYxMTDC3siR632/UaTSc/mE3nz61nJTwSN1fFLVV1ez483uYW1kyf9WLTH74AcbcfTvuQQH8uuFz3WidrMRk7N364T9We2HTb8woRt85l4KMLO0NSwYGbFr5BuE/76W8qJif1v+Tzave4MiW7Zz8/hcAkk+dwcrBvtnskupAf9JjL/11U6fRsPPP71FTVcWcl57FQe2GrYsz544e17aug/x12zY+/clj6CBcfLyIahjBNHTGLVSVl3No01bG3TMfB7Ubw2+bDgr8/cGlrBhxE3+aeYfug7YwIwv7fk0CPCGZixdS6efvqxs+ae/Wj2EzbuGZL/6JsZkpVo4OeA7VPvDE2skRe3Vf3fnsyBDNa0meSi9EKwobRqKUXszTtbIbW+KgHf7nN3YURVnZunVnDxxudV/lBUX0sbbW3bTUFkVR2L/xK93XFyK1Ad1/cBBZ8YlYOdhzx6svEzhxLOfDo3TzvjQK3fat7t+p0TG4eHtx7lhYi+M0TmMQf+wEMb8d4eL5VMbcNU/3en56Bqd++EX3dU5iMiqVCrdAP9Ji4nAPCsA9KIAf3/+YuMPHsHZ2pDArm82r3sTM0oLKkhLij4UR3+TYyae03T3eI4aRm3IBU4s+OHn25+T3PzerraygkF//9W/mvPQsZhbaoXz7Pv0S/3Gj8Rw6mAsR2nPo6uMJaP+yUalUXIg8S8CEMTio3Th35DgHv9rCxAfuYeCUifiNHUXyqXDOR7ScHrkgMwvvkcFY2tth5WBPVoL2DuGm7N36EjhpPF7Dh3Lzww+gahhaemLnD9z00L14DNFe7D574BB+40ZhoFKh1Ne3OFZXkAAXohWNY8GLL+bpJtfKT78U4Ic3b6MgI1M35PByygqLsHPrS0Zs/BXVkJ+WTnlRMR6DB3J8+y5mPL2EoJvGcfSbnRz8astl37vtjTXYuDijqa5u8VrJxTz2f/YVZ/cfQqmvZ+3tC1AZGmJpZ0vwrdNICY9qdlNUdsNcMwD7P/2Se95Yhbm1FeE/7aEwK5vMcwmA9u7Xxuej/l5eajr56ZmMvXs+J3b+oHvIRdMWeKODm77BxceLUfNnU5pfQFLYafLS0nWjgkDbAs9OSsHc0hIbFyeyE5PITkzBQe1GQmgYBRlZZMTFM/au23H28uBEw4yXv1eYmY25lSX+40br6mmcBiE1Oob+g4Kw7+eqm1DtlqUPY2RszOmGu39veuhevIYNobK0jLO/HW7o0vEiKz6pzZ/NtSQBLkQrGoO5JDeP6ooKft3wBWcPHNK9XlVWzukf93RoXxmx56gsLW3RYu6I1OgY+g8ZiLWzEyHzbuX4ju/5bu377b4v81yCLlhb8+O6j3T/rq+ro76ujqKcXP73700tts1Py0BTU4ORiQlJJ8M5vvN7bF1dKGzy10dH/PC3D1n0tz8z7t75GBhoe28b/xpoql5Txzf/9ydifjus68ZJCgtn+G3T8Rs7ivhjJ3Dx8iQzPpHywiJG3TGHnOQL5CQlM3DyBOIb5oQ/+79DTH/yUQDiQ0+0WlNjV9mI2TPQ1NaSGhWDha019fX1hP+0Fwe3ftir3XD28iB6/2/4jgkh+WQ4W17946W+cz8fcpLP67q03AcGSYAL0ZMKs7KIP3ZCN7rk5w/+2el97fxL6yMZOiI18iz+T4zm4XV/wUCl4sDnLQO2q9XX1ZGTfB5jU1PKC4v4/t2/d2o/kXv/R9zhUGYte4L81AyKcy5Sll/Y5vaN/dqgDX91oD+L/66dSsHB3Y3wX37l0H++4fSPu9FUV3Psv99RWlCom50yev9Bpj/5KCV5+W0GamFDgPuOCSE1KgZNdTXFORdZf/+jZMYnMPy26XgPH4ppnz7EHTnOtrfeoaKoRPuB19CPrjI0pCgnl/zUdCpLSnEfFMiJna23+K81uYgpRCvqNXX8a+lzzWY47AnHtu4k9uBR+vkN4MTOHzrUZdMVvnvnff771jtXvZ9tb64hN/kCboF+uod7dERFcQn/XPIsFUUl3P+n11AZGpKbfJ6K4hJSwiMB7Rj9g19e6lpqfDhJ07+cfq/xfKoMDUk5HaFbnx4TR72mjoKMLN0wxdzk85TlF+r+KqitqqasQPsBVJSdg6Io2msEgwI7/H1dLWmBC9GLleYX8NmzL6MyMkSp654LY61pOub8ahRl5/DBg0sIvnUamecSr+i9FcUl7P/sK+av0t7x2LRvvi3r738UzWXu4q0oLqGqvBwzCwtSwiNavN70AzOn4aElTRVm52Bpb6e7TpIWHcvkRQtwcFcz/QntU6kqS1q/LnAtSAtcCD1Qr6lr8xF3+kapr+f0D7t1j+O7EqHbd1FyMY/6+nouXkhrd/vqiop2p2EobLhg3dpDvBu7WCqKS1rt7inK0najNHanpEXHYGhsxMPr/szIubMYOffKJym7EhLgQgi9oamuZsef3uXQpq2tjrDpjJzk82TExTebAqFRfkambpvWNF7ILcrWDjVNi9bOfNk4yuZK5rfpDOlCEULolah9vzW7wHm1tr+9ttWHO8Cl+wFy2w3whpZ4Ti4lefkYmRhzZMt2pi19BMf+6queO78tEuBCiBtaW2PXAfIzsqgoLmm1ewUg/Ke9GBmbcPF8qm7drrXrqSqvICMunlseW8Tw22a0uEP3WlK6awkLC+u2Y8kiiyyyXIvF2My00+9d8vE65c/H9yveI4ZdVQ1tZaf0gQshxGU0fWrUlfr61bcoys7hsY/ea3Yn6bUiAS6EEF2kLL+Qjx99hvNnoijNL7jm+5c+cCGE6EKlefl88vjzXbJvaYELIYSekgAXQgg91W6Ab9y4kZycHKKiWg6jWb58OYqi4ODg0CXFCSGEaFu7Af75558zc+bMFuvVajXTpk3jwoULXVKYEEKIy2s3wA8dOkRBQcurp+vWreOVV165buZnEEIIfdOpUShz5swhIyODyMjIdrddsmQJS5cuBcDR0bEzhxNCCNGGdu8C8vDwUKKiohRAMTc3V0JDQxVra2sFUFJSUhQHB4eruptIFllkkUWWtpdrdiemj48PXl5eREREkJKSglqt5vTp07i4uFzproQQQlyFK+5CiY6ObhbWKSkpjBw5kvz8/Hbf6+HhQVhYy6dkd4SjoyN5eXmdem9X6q11Qe+tTeq6Mr21Lui9tV1vdXl4eLT52mWb7ps3b1YyMzOVmpoaJS0tTVm8eHGz16+kC+Vqlt7a/dJb6+rNtUld10ddvbm2G6WudlvgCxYsuOzrXl5e7e1CCCFEF5A7MYUQQk8ZAm/0dBEddfr06Z4uoVW9tS7ovbVJXVemt9YFvbe2G6EuA7R9KUIIIfSMdKEIIYSekgAXQgg9pRcBPmPGDOLi4khISGDFihU9VodarWb//v3ExMQQHR3NsmXLAHj99ddJT08nPDyc8PBwZs2a1e21paSkEBkZSXh4uG6svZ2dHXv27CE+Pp49e/Zga2vbrTX5+fnpzkl4eDjFxcU899xzPXa+WptZ83LnaP369SQkJBAREUFwcHC31rV27VpiY2OJiIhgx44d2NjYANrxwBUVFbpz9/HHH3drXZf72a1cuZKEhATi4uKYPn16t9a1ZcsWXU0pKSmEh4cD3Xu+2sqHrv4d6/GxkZdbVCqVkpiYqHh5eSnGxsbKmTNnlMDAwB6pxdXVVQkODlYAxdLSUjl37pwSGBiovP7668ry5ct79Dy1Nh7/nXfeUVasWKEAyooVK5Q1a9b06M8xKytL6d+/f4+dr4kTJyrBwcG6aSEud45mzZql/PTTTwqgjB49WgkNDe3WuqZNm6YYGhoqgLJmzRpdXU2nteiJ89XWzy4wMFA5c+aMYmJionh6eiqJiYmKSqXqtrqaLu+++67y2muvdfv5aisfuvJ3rNe3wEeNGkViYiIpKSnU1tayZcsW5s2b1yO1ZGdn6z7Zy8rKiI2Nxc3NrUdq6Yh58+bxxRdfAPDFF19w++2391gtt9xyC0lJSaSmpvZYDa3NrNnWOZo3bx5ffvklAMePH8fW1hZXV9duq2vv3r3U1dUBEBoailqt7pJjX2ldbZk3bx5btmyhpqaG8+fPk5iYyKhRo3qkrnvuuYevv/66S459OW3lQ1f+jvX6AHdzcyMtLU33dXp6eq8ITQ8PD4KDgzl+/DgAzzzzDBEREWzcuLHbuyoAFEVhz549nDx5kiVLlgDg4uJCdnY2oP3lcnZ27va6Gt13333N/qfq6fPVqK1z1Jt+7xYvXszPP/+s+9rLy4vTp09z4MABJkyY0O31tPaz6y3na+LEieTk5JCYmKhb1xPnq2k+dOXvWK8PcAMDgxbrenoOcgsLC7Zv387zzz9PaWkpH3/8MT4+PgwbNoysrCzee++9bq9p/PjxjBgxglmzZvH0008zceLEbq+hLcbGxsydO5dt27YB9Irz1Z7e8nu3evVqNBoNmzZtAiArK4v+/fszfPhwXnzxRTZv3oyVlVW31dPWz663nK/777+/WUOhJ87X7/OhLdfinPX6AE9PT8fd3V33tVqtJjMzs8fqMTIyYvv27WzatImdO3cCkJubS319PYqisGHDhi770/FysrKyALh48SI7d+5k1KhR5OTk6P4kc3V1JTc3t9vrApg1axanT5/WHb83nK9GbZ2j3vB7t3DhQmbPns0DDzygW1dTU6PrPjh9+jRJSUn4+fl1W01t/ex6w/kyNDTkjjvu4JtvvtGt6+7z1Vo+dOXvWK8P8LCwMHx9ffH09MTY2Jj77ruPXbt29Vg9GzduJDY2lnXr1unWNe23mj9/PtHR0d1aU58+fbC0tNT9e/r06URHR7Nr1y4WLVoEwKJFi/juu++6ta5Gv28V9fT5aqqtc7Rr1y4WLlwIwOjRoykuLtb9GdwdZsyYwYoVK5g7dy6VlZW69Y6OjqhU2v9tvby88PX1JTk5udvqautnt2vXLu677z5MTEzw9PTE19eXEydOdFtdAFOnTiUuLo6MjAzduu4+X63lQ1f/jnXLFdqrWWbNmqWcO3dOSUxMVFavXt1jdYwfP15RFEWJiIhQwsPDlfDwcGXWrFnKl19+qURGRioRERHKd999p7i6unZrXV5eXsqZM2eUM2fOKNHR0bpzZG9vr/z6669KfHy88uuvvyp2dnbdfs7Mzc2VvLw83QNAgB47X63NrHm5c/Thhx8qiYmJSmRkpDJixIhurSshIUFJTU3V/Z59/PHHCqDccccdSnR0tHLmzBnl1KlTyuzZs7u1rsv97FavXq0kJiYqcXFxysyZM7u1LkD597//rTz++OPNtu3O89VWPnTl75jcSi+EEHqq13ehCCGEaJ0EuBBC6CkJcCGE0FMS4EIIoackwIUQQk9JgAshhJ6SABdCCD31/9KTPjm0kIfPAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling the Network\n",
    "To sample we give the network a letter and ask what the next one is, feed that in as the next letter, and repeat until the EOS token.\n",
    "\n",
    "Create tensors for input category, starting letter, and empty hidden state\n",
    "Create a string output_name with the starting letter\n",
    "Up to a maximum output length,\n",
    "Feed the current letter to the network\n",
    "Get the next letter from highest output, and next hidden state\n",
    "If the letter is EOS, stop here\n",
    "If a regular letter, add to output_name and continue\n",
    "Return the final name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "def sample(category, start_letter='A'):\n",
    "    with torch.no_grad():\n",
    "        category_tensor = categoryTensor(category)\n",
    "        input = inputTensor(start_letter)\n",
    "        hidden = rnn.init_hidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for idx in range(max_length):\n",
    "            output, hidden = rnn(category_tensor.to(gpu_device), \n",
    "            input[0].to(gpu_device), hidden.to(gpu_device))\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == num_letters - 1:\n",
    "                break\n",
    "            else:\n",
    "                letter = all_letters[topi]\n",
    "                output_name += letter\n",
    "            input = inputTensor(letter)\n",
    "        \n",
    "        return output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get multiple samples from one category and multiple starting letters\n",
    "def samples(category, start_letters='ABC'):\n",
    "    for start_letter in start_letters:\n",
    "        print(sample(category, start_letter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Rovakov\nUantovov\nSantovovev\n-----------------------------------------------------------------------------------------\nGertan\nEring\nRoun\n-----------------------------------------------------------------------------------------\nSandera\nPare\nAllan\n-----------------------------------------------------------------------------------------\nCha\nHan\nIuan\n-----------------------------------------------------------------------------------------\nWanton\nBander\nOllan\n"
    }
   ],
   "source": [
    "samples('Russian', 'RUS')\n",
    "print(\"-\" * 89)\n",
    "samples('German', 'GER')\n",
    "print(\"-\" * 89)\n",
    "samples('Spanish', 'SPA')\n",
    "print(\"-\" * 89)\n",
    "samples('Chinese', 'CHI')\n",
    "print(\"-\" * 89)\n",
    "samples(\"English\", 'WBO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}