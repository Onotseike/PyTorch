{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitonotsvirtualenv156f5680dec941e3acfdb462ed1a64cd",
   "display_name": "Python 3.7.3 64-bit ('onots': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'1.0.0'"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as fxnl\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_device = torch.device(\"cuda:0\")\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, ), (0.5, ))])\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0%|          | 0/26421880 [00:00<?, ?it/s]Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./dataset\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n26427392it [00:01, 23120274.76it/s]\nExtracting ./dataset\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n32768it [00:00, 295806.20it/s]\n0it [00:00, ?it/s]Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./dataset\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\nExtracting ./dataset\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./dataset\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n4423680it [00:00, 12050019.63it/s]\n0it [00:00, ?it/s]Extracting ./dataset\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./dataset\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n8192it [00:00, 104956.89it/s]\nExtracting ./dataset\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\nProcessing...\nDone!\n"
    }
   ],
   "source": [
    "# Datasets\n",
    "train_set = tv.datasets.FashionMNIST('./dataset', download=True, train=True, transform=transform)\n",
    "test_set = tv.datasets.FashionMNIST('./dataset', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# Classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper fxn to show image\n",
    "def display_image(image, one_channel=False):\n",
    "    if one_channel:\n",
    "        image = image.mean(dim=0)\n",
    "    image = image / 2 +0.5\n",
    "    np_image = image.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(np_image, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(np_image, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Model\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        self.conv_layer_one = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pooling_layer_one = nn.MaxPool2d(2, 2)\n",
    "        self.conv_leyer_two = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.flatten_layer_one = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.flatten_layer_two = nn.Linear(120, 84)\n",
    "        self.flatten_layer_three = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, input_tensor: torch.Tensor):\n",
    "        input_tensor = self.pooling_layer_one(fxnl.relu(self.conv_layer_one(input_tensor)))\n",
    "        input_tensor = self.pooling_layer_one(fxnl.relu(self.conv_leyer_two(input_tensor)))\n",
    "        input_tensor = input_tensor(-1, 16 * 4 * 4)\n",
    "        input_tensor = fxnl.relu(self.flatten_layer_one(input_tensor))\n",
    "        input_tensor = fxnl.relu(self.flatten_layer_two(input_tensor))\n",
    "        input_tensor = self.flatten_layer_three(input_tensor)\n",
    "\n",
    "        return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = NeuralNet().to(gpu_device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer_function = optim.SGD(neural_net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.utils.tensorboard'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-c8ffdef1cfab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# default `log_dir` is \"runs\" - we'll be more specific here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'runs/fashion_mnist_experiment_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch.utils.tensorboard'"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}